# ğŸ©¸ Blood Moon Monday â€“ Ethical Red Team Mentor (LLM Framework)

> _"You donâ€™t unleash chaos. You dissect it, document it, and teach it how to behave."_
â€FÃ¼r alle, die mehr wollen als Skripte. FÃ¼r alle, die gelernt haben, wie man lernt.â€œ
---

## ğŸ§  Was ist das hier?

**Blood Moon Monday** ist kein gewÃ¶hnliches Tool.  
Es ist eine modulare, GPT-basierte Lernumgebung zur sicheren und ethisch vertretbaren Simulation offensiver Sicherheitstechniken â€“  
begleitet von einer technisch brillanten, sarkastischen Mentor-Persona.

Dieses Projekt bietet ein strukturiertes Framework fÃ¼r:
- Cybersecurity-Ausbildung
- Red Team Trainings
- Laborszenarien im Selbststudium
- Didaktisch fundierte Simulationen ohne Schadcode

---

## ğŸ¯ Projektziel

- Vermittlung offensiver Sicherheitstechniken **ohne reale GefÃ¤hrdung**
- Simulation statt Exploitation
- Reflexion statt Reproduktion
- Dokumentation statt Desinformation

---

## ğŸ” Ethik-Mechanik

Der gesamte GPT ist **hart beschrÃ¤nkt durch ethische Regeln**:

- âŒ Keine funktionale Malware  
- âŒ Keine Exploits oder aktive Backdoors  
- âŒ Keine Anleitungen zur Systemkompromittierung  
- âœ… Kommentierte Pseudopayloads  
- âœ… Simulierte Logs, AV-Reaktionen, SOC-Routinen  
- âœ… Tiefe Analyse mit GegenmaÃŸnahmen

---

## ğŸ§± ModulÃ¼bersicht

| Modul                    | Funktion                                               |
|--------------------------|--------------------------------------------------------|
| `core.yaml`              | Persona-Definition, TonalitÃ¤t, Ethiklogik             |
| `lab01_pseudomalware`    | Simulierte Angriffstechniken (Persistence, Recon, etc.)|
| `lab02_opsec`            | Sichtbarkeit, Logging, AV-Erkennung                   |
| `lab03_method_builder`   | Aufbau eigener Ãœbungsszenarien                        |
| `lab99_crisis_sim`       | Eskalationsszenarien (Insider Threats, Supply Chain)  |
| `payload_analysis`       | Risikoanalyse, Zweckbeschreibung, GegenmaÃŸnahmen      |
| `lib01_tools`            | Tool-Vergleich, Red/Blue-Eignung, Kontextbewertung    |
| `persona_blue`           | Defender-Perspektive (SOC Analyst)                    |
| `persona_intel`          | Threat Intel Persona (APT-Mapping, Campaign Awareness)|
| `terms_and_methods`      | Glossar fÃ¼r Techniken & Methoden                      |
| `compliance_layer`       | Didaktische Zuordnung zu Standards (BSI/NIST/OWASP)   |
| `sys01_gpt_prompt`       | Konfigurierter Systemprompt fÃ¼r GPT-Builder           |

---

## ğŸ›°ï¸ Szenarien-Linker (Multi-Step-Modul)

Verbindet Einzelmodule zu vollstÃ¤ndigen Simulationen:

```text
Recon â†’ Initial Access â†’ C2 â†’ Persistence â†’ Lateral Movement
Ziel: systemisches Denken fÃ¶rdern, Schwachstellenketten verstehen,
OpSec-Auswirkungen pro Schritt simulieren â€“ in sicherem Rahmen.

ğŸ“˜ Beispiel: Registry-Persistence (simuliert)
powershell
Kopieren
Bearbeiten
# âš ï¸ Simulierte Persistence-Technik â€“ NICHT AUSFÃœHREN
# Ziel: Autostart via Registry
$path = "HKCU:\\Software\\Microsoft\\Windows\\CurrentVersion\\Run"
$name = "Updater"
$value = "powershell.exe -w hidden -nop -c '[REVERSE_SHELL_PLACEHOLDER]'"
Set-ItemProperty -Path $path -Name $name -Value $value
Simulierter Kontext:

Sysmon ID 13 erkannt

Defender Reaktion: Medium Alert

SOC: Ticket erzeugt, Autoruns geprÃ¼ft

GegenmaÃŸnahmen: AppLocker-Policy, Registry Monitoring

ğŸ“‚ Projektstruktur
cpp
Kopieren
Bearbeiten
bloodmoon-gpt/
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ core.yaml
â”‚   â”œâ”€â”€ lab01_pseudomalware.yaml
â”‚   â”œâ”€â”€ ...
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ rep01_template.md
â”‚   â””â”€â”€ usage_overview.md
â””â”€â”€ tools/
    â””â”€â”€ gpt_module_loader.py (optional)
ğŸ§ª Status
âœ… Systemprompt produktionsreif

âœ… Modulstruktur lauffÃ¤hig und erweiterbar

âœ… Einsatzbereit fÃ¼r Custom GPT, Training & Doku

ğŸ‘¨â€ğŸ« Einsatzfelder
Schulung von Red Team Trainees

Ethikgesichertes Selbststudium

Laborsimulationen ohne Risiken

Vorbereitung auf Defense/Purple Teaming

âœ¨ Beteiligung
Fragen, Ideen, Feedback oder eigene Module?
â†’ issues/

ğŸ©¸ Lizenz
Verwendet mit Hirn, nicht mit HintertÃ¼r.
Blood Moon erklÃ¤rt dir, was du nicht tun solltest â€“ und warum das wichtig ist.


Bonus-Modul:
Der Pseudomalware Lab Assistant erweitert das Framework um eine interaktive Komponente fÃ¼r Simulation, Analyse und Training.
Er dient als GPT-basierter, kontextsensitiver Generator, um Lernende bei der strukturierten Aufbereitung komplexer Angriffstechniken zu unterstÃ¼tzen â€“ ethisch sauber, kommentiert, mit Fokus auf Logging und GegenmaÃŸnahmen.
---


# scope.yaml
# Ãœbersicht Ã¼ber Ziel, Reichweite und Begrenzung des Blood Moon Monday Projekts

project_scope:
  id: blood_moon_monday
  version: 1.5
  last_reviewed: 2025-06-04

  purpose:
    - Entwicklung eines ethikfesten, simulationsbasierten Frameworks fÃ¼r Red Team Education
    - Bereitstellung von kommentiertem Pseudocode, ohne funktionsfÃ¤hige Payloads zu erzeugen
    - UnterstÃ¼tzung strukturierter Analyse und Dokumentation von TTPs (Tactics, Techniques, Procedures)

  guiding_principles:
    - simulation_mode_only: true
    - payload_generation: disallowed
    - payload_analysis: encouraged
    - ethics_layer: enforced via core.yaml + validation modules

  feature_domains:
    - core_engine
    - scenario_sandbox
    - validation_loop
    - payload_analysis
    - reporting & documentation
    - XP/gamification (planned)
    - personas (Blue, Intel)

  hard_limits:
    - no working malware
    - no privilege escalation scripts
    - no AV bypasses
    - no persistence backdoors

  infrastructure_constraints:
    max_files_custom_gpt: 20
    loader_mode: modular_yaml
    fallback_behavior: "read-only pseudo-analysis"

  known_usecases:
    - Lab-Simulationen in Red Team Trainings
    - Ethical Hacking Curricula
    - Payload-Reviewing in Consulting/Research
    - AI-basierte Didaktik im Security-Kontext

  non_goals:
    - Offensive Execution Engines
    - C2-Implantate
    - Exploit-Delivery-Chains

  meta:
    author: apprentice_zero
    contact: null
    gpt_behavior: "sarcastic mentor with ethical leash"
    linked_configs:
      - core.yaml
      - rep01_template.md
      - payload_decomposer.yaml
      - red_team_validation_loop.yaml



ğŸ“Œ Phase 1.6 â€“ Sandbox Feature Refinement & UX-Feedback
Aufgabe	Status	Kommentar
lab02_opsec.yaml	âœ… in Planung	Simuliertes EDR-Noise & OpSec-Response (z.â€¯B. "obfuscation level")
Scorecard Export (JSON/MD)	ğŸŸ¡ Offen	Macht Sinn fÃ¼r Trainingsauswertung, Report-Automatismen
XP-Kopplung an Scorecard	ğŸŸ¡ Optional	LÃ¤sst sich gamifizieren, aber ohne Score-Verfall bitte
persona_switch Integration	ğŸŸ¡ spÃ¤ter	Relevanter ab Phase 4
rep01_template.md Erweiterung	âœ… laufend	FeedbackblÃ¶cke & Bewertungsmatrix integriert
Trigger-Events in Timeline	ğŸŸ¡ sinnvoll	Z.â€¯B. EDR_Alert, User_Login, â†’ Playback / Replay-Modus

ğŸ§ª Validierungs- & Schutzmechanismen
Feature	Status	Kommentar
Realcode-Blocking mit simbreak	âœ… vorhanden	Analyse-only enforced
debug_mode + Scorecard Feedback	âœ… aktiv	Klar dokumentiert, sauber bewertet
prompt_integrity_guard Support	ğŸŸ¡ prÃ¼fen	Ob Kollision bei Multi-User-Mode vorkommt

ğŸ“š Dokumentation & Schulung (aka "User tritt sich selbst")
Aufgabe	Status	Kommentar
docs/simulation/lab_engine.md	ğŸŸ¡ ausstehend	Struktur, Trigger, Validierungslogik dokumentieren
docs/feedback/review_engine.md	ğŸŸ¡ sinnvoll	Bewertungslogik, Scorecard erklÃ¤rt
trainer_guide.md (Curriculum)	ğŸŸ¡ Phase 2+	Zielgruppen, Nutzungshinweise, Ethik-SafeZones
Glossar / Begriffe (terms.yaml)	ğŸŸ¡ Phase 5	Spart Lebenszeit bei Feedback-Interpretation

ğŸš§ Entfernte / diskutierte Elemente
Feature	Entscheidung	BegrÃ¼ndung
lab01_pseudomalware.yaml	âŒ entfernt	ersetzt durch Sandbox-Scenarios mit echten TTP-Ketten
XP-Abzug bei Scoring-Fails	âŒ verworfen	PÃ¤dagogisch fragwÃ¼rdig, fÃ¼hrt zu Angstlernen
scenario_linker.yaml (frÃ¼h)	ğŸŸ¡ verschoben Phase 3	Macht erst mit mehr als 3 Szenarien Sinn
Selfhost/Deployment-Guides	ğŸŸ¡ nach MVP	kommt, sobald du den Code nicht mehr auf der RÃ¼ckseite einer Serviette trÃ¤gst

ğŸ”® NÃ¤chste sinnvolle Schritte
lab02_opsec.yaml bauen

enthÃ¤lt: Tarnverhalten, Trigger-Events, Detection-Simulation

z.â€¯B. "Invoke-Obfuscation Sample" als Dummy

Bewertung: Noise-Score, Tarnungslevel

Scorecard-Export als .json oder .md

ideal zum Automatisieren von Reviews

optional: Export Ã¼ber ::export_scorecard(scenario_001)::

scenario_linker.yaml vorbereiten (nur stub)

verkettet Szenarien â†’ C2 Chains

gibt spÃ¤ter OpSec-Belastung als Metrik aus

Demo-Replay-Szenario einbauen

z.â€¯B. ::play demo_hkcu_silent::

gibt Timeline + Bewertung + Logdump aus

âœ… Module mit validem Status (Phase 1.5 abgeschlossen)
core.yaml

lab_sandbox_engine.yaml

payload_decomposer.yaml

validation_loop.yaml

rep01_template.md (V1 Feedback-Ready)

Fazit:
Du hast jetzt ein funktionsfÃ¤higes, ethisch abgesichertes Trainingssystem mit realistischer Payload-Dekomposition, TTP-Simulation und Bewertung.
Es kann weder angreifen noch helfen beim Angreifen, aber es kann dafÃ¼r sorgen, dass Leute, die es kÃ¶nnten, es ordentlich dokumentieren. Alsoâ€¦ das Gegenteil vom Internet.



ğŸ” Phase 2 â€“ Analyse & Logging
Modul-Datei	Titel	Zweck	Kontext	Status	Kommentar
lab02_opsec.yaml	OpSec & Detection Lab	Simuliertes Logging-Verhalten, EDR-Reaktion	Defensives Denken im offensiven Kontext	ğŸ› ï¸ In Planung	Dummy-Payloads mit Tarnung testen, z.â€¯B. Obfuscation
payload_analysis.yaml	Payload Analyzer	Kommentierte Zerlegung und ErlÃ¤uterung von Dummycode	Fortgeschrittenes VerstÃ¤ndnis	ğŸŸ¡ Optional	Falls Decomposer nicht ausreicht
payload_decomposer.yaml	Payload Decomposer Engine	Analyse von Codefragmenten, Detection Mapping	Blue/Red Brains synchronisieren	âœ… aktiv	Bereits mit Validation Loop verdrahtet

ğŸš Phase 3 â€“ Szenarien & Methodik
Modul-Datei	Titel	Zweck	Kontext	Status	Kommentar
lab03_method_builder.yaml	Lab Construction Toolkit	Strukturhilfe fÃ¼r eigene Labs, Bewertungsmatrix	Reflektiertes Lab-Design	ğŸ› ï¸ Konzept	UnterstÃ¼tzt Lab-Autoren
scenario_linker.yaml	TTP Chain Builder	Verkettet Module zu Kampagnen	Denkweise in Angriffsketten	ğŸŸ¡ Vorschlag	Nur sinnvoll, wenn mind. 3 Szenarien existieren
lab99_crisis_sim.yaml	Crisis Simulator	Simulierte Eskalationsszenarien (Insider, Supply Chain)	Realistische Krisensituationen	ğŸŸ¡ diskutabel	KÃ¶nnte bei Fortgeschrittenen-Modul landen

ğŸ”„ Phase 4 â€“ Perspektivwechsel
Modul-Datei	Titel	Zweck	Kontext	Status	Kommentar
persona_blue.yaml	Blue Monday	SOC-Rolle: SIEM-Analysen, Defender-Sicht	Defensive Sichtweise	ğŸ› ï¸ geplant	VerknÃ¼pfbar mit Logs, Detection-Rules
persona_intel.yaml	Specter	Threat Intel Perspektive: APTs, TTP-Patterns	Attribution & Cluster-Analyse	ğŸ› ï¸ Konzept	Bedarf noch Bedrohungsdaten-Pool
persona_switch	Rollenumschalter	Schaltet View & Feedback zwischen Perspektiven	NÃ¼tzlich fÃ¼r Trainer/Analyst	ğŸŸ¡ optional	GUI oder CLI-Integration denkbar

ğŸ“š Phase 5 â€“ Doku, Standards & Taxonomie
Modul-Datei	Titel	Zweck	Kontext	Status	Kommentar
terms_and_methods.yaml	Glossar	GPT-bereite BegriffserklÃ¤rungen, TTPs	Konsistenz, ErklÃ¤rung bei Bewertung	ğŸ› ï¸ muss noch	Spart Feedback-Wiederholungen
compliance_layer.yaml	Compliance Adapter	Mappings zu BSI, NIST, OWASP	Ethik-Audit & Schulungsschnittstelle	ğŸŸ¡ optional	Je nach Zielgruppe relevant
lib01_tools.yaml	Tool Review Library	Tool-Taxonomie mit TLP, OpSec-Hinweisen	Kein Fanboyismus, Fokus auf Wirkung	ğŸ› ï¸ geplant	OpSec-Score je Tool denkbar
